{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":145178,"status":"ok","timestamp":1651646538632,"user":{"displayName":"Jenish Thanki","userId":"03754303524867663253"},"user_tz":420},"id":"-mOxaAGWQyih","outputId":"50ab507f-a661-4e81-9dfe-0da329070ab5"},"outputs":[{"name":"stdout","output_type":"stream","text":["2.8.0\n","MainFolder : raw-img\\cane\n","MainFolder : raw-img\\cavallo\n","MainFolder : raw-img\\elefante\n","MainFolder : raw-img\\farfalla\n","MainFolder : raw-img\\gallina\n","MainFolder : raw-img\\gatto\n","MainFolder : raw-img\\mucca\n","MainFolder : raw-img\\pecora\n","MainFolder : raw-img\\ragno\n","MainFolder : raw-img\\scoiattolo\n"]}],"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","import os\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import cv2\n","from sklearn.model_selection import train_test_split\n","\n","print(tf.__version__)\n","import keras\n","from keras.datasets import cifar10\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n","##from keras.utils import to_catergorical\n","from keras.utils.np_utils import to_categorical\n","#from google.colab import drive\n","\n","\n","#drive.mount('/content/drive')\n","\n","translate = {\"cane\": \"dog\", \"cavallo\": \"horse\", \"elefante\": \"elephant\", \"farfalla\": \"butterfly\", \"gallina\": \"chicken\",\n","             \"gatto\": \"cat\", \"mucca\": \"cow\", \"pecora\": \"sheep\", \"scoiattolo\": \"squirrel\", \"dog\": \"cane\",\n","             \"cavallo\": \"horse\", \"elephant\": \"elefante\", \"butterfly\": \"farfalla\", \"chicken\": \"gallina\", \"cat\": \"gatto\",\n","             \"cow\": \"mucca\", \"spider\": \"ragno\", \"squirrel\": \"scoiattolo\"}\n","\n","# X is the array of images\n","# y is the labels\n","X = []  # images\n","y = []  # labels\n","i = 0  # variable to name labels.. since we have different names such as \"cane\", \"dog\" we gotta assign numbers to differentiate\n","\n","# iterate over files in that directory\n","for filename in os.listdir('raw-img'):\n","    e = 0  # for testing purposes since we only want some picture to see output\n","    animalFolder = os.path.join('raw-img', filename)\n","    print(\"MainFolder : {}\".format(animalFolder))\n","    # checking if it is a file\n","    for picture in os.listdir(animalFolder):\n","        e += 1\n","        pathPicture = os.path.join(animalFolder, picture)\n","        # print(pathPicture)\n","        img = mpimg.imread(pathPicture)\n","        # resized the image to 128x 128 since the images size varies on the folder provided\n","        resized_img = cv2.resize(img, (128, 128), interpolation=cv2.INTER_NEAREST)\n","        # resized_img = tf.cast(resized_img, np.uint8)\n","\n","        # some images are corrupted. Therefore a validation set is necessary to avoid error\n","        # populating the matrix of each image into X and the label into y accordingly\n","        if resized_img.shape == (128, 128, 3):\n","            X.append(resized_img)\n","            y.append(i)\n","        \n","    i += 1\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yV1dh01aoy5H","outputId":"8981540f-7bd9-4245-8e27-da97e162b1ff"},"outputs":[{"name":"stdout","output_type":"stream","text":["X numpy array:  <class 'numpy.ndarray'> (26128, 128, 128, 3)\n","y numpy array:  <class 'numpy.ndarray'> (26128,)\n","X_train:  (18289, 128, 128, 3)\n","X_val:  (7839, 128, 128, 3)\n","y_train:  (18289,)\n","y_val:  (7839,)\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 128, 128, 32)      896       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 63, 63, 32)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n","                                                                 \n"," flatten (Flatten)           (None, 57600)             0         \n","                                                                 \n"," dense (Dense)               (None, 512)               29491712  \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 29,562,410\n","Trainable params: 29,562,410\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/30\n","286/286 [==============================] - 293s 1s/step - loss: 1.9718 - accuracy: 0.3079 - val_loss: 1.6784 - val_accuracy: 0.4114\n","Epoch 2/30\n","286/286 [==============================] - 281s 981ms/step - loss: 1.6741 - accuracy: 0.4136 - val_loss: 1.4759 - val_accuracy: 0.4895\n","Epoch 3/30\n","286/286 [==============================] - 275s 963ms/step - loss: 1.4987 - accuracy: 0.4809 - val_loss: 1.2990 - val_accuracy: 0.5460\n","Epoch 4/30\n","286/286 [==============================] - 274s 958ms/step - loss: 1.3188 - accuracy: 0.5475 - val_loss: 1.2373 - val_accuracy: 0.5776\n","Epoch 5/30\n","286/286 [==============================] - 286s 999ms/step - loss: 1.1346 - accuracy: 0.6132 - val_loss: 1.1765 - val_accuracy: 0.6012\n","Epoch 6/30\n","286/286 [==============================] - 289s 1s/step - loss: 0.9710 - accuracy: 0.6677 - val_loss: 1.1919 - val_accuracy: 0.6184\n","Epoch 7/30\n","286/286 [==============================] - 289s 1s/step - loss: 0.8074 - accuracy: 0.7218 - val_loss: 1.2507 - val_accuracy: 0.6139\n","Epoch 8/30\n","286/286 [==============================] - 288s 1s/step - loss: 0.6529 - accuracy: 0.7786 - val_loss: 1.3303 - val_accuracy: 0.6237\n","Epoch 9/30\n","286/286 [==============================] - 285s 995ms/step - loss: 0.5188 - accuracy: 0.8213 - val_loss: 1.3400 - val_accuracy: 0.6250\n","Epoch 10/30\n","286/286 [==============================] - 289s 1s/step - loss: 0.4169 - accuracy: 0.8565 - val_loss: 1.4056 - val_accuracy: 0.6195\n","Epoch 11/30\n","286/286 [==============================] - 290s 1s/step - loss: 0.3399 - accuracy: 0.8851 - val_loss: 1.4944 - val_accuracy: 0.6427\n","Epoch 12/30\n","286/286 [==============================] - 290s 1s/step - loss: 0.2931 - accuracy: 0.9002 - val_loss: 1.5641 - val_accuracy: 0.6429\n","Epoch 13/30\n","286/286 [==============================] - 290s 1s/step - loss: 0.2514 - accuracy: 0.9147 - val_loss: 1.5057 - val_accuracy: 0.6369\n","Epoch 14/30\n","286/286 [==============================] - 287s 1s/step - loss: 0.2170 - accuracy: 0.9291 - val_loss: 1.8187 - val_accuracy: 0.6396\n","Epoch 15/30\n","286/286 [==============================] - 274s 959ms/step - loss: 0.1989 - accuracy: 0.9344 - val_loss: 1.6178 - val_accuracy: 0.6438\n","Epoch 16/30\n","286/286 [==============================] - 274s 960ms/step - loss: 0.1981 - accuracy: 0.9349 - val_loss: 1.7719 - val_accuracy: 0.6459\n","Epoch 17/30\n","286/286 [==============================] - 282s 985ms/step - loss: 0.1567 - accuracy: 0.9470 - val_loss: 1.9381 - val_accuracy: 0.6460\n","Epoch 18/30\n","286/286 [==============================] - 290s 1s/step - loss: 0.1596 - accuracy: 0.9465 - val_loss: 1.8285 - val_accuracy: 0.6403\n","Epoch 19/30\n","286/286 [==============================] - 290s 1s/step - loss: 0.1451 - accuracy: 0.9539 - val_loss: 1.8789 - val_accuracy: 0.6422\n","Epoch 20/30\n","286/286 [==============================] - 290s 1s/step - loss: 0.1371 - accuracy: 0.9544 - val_loss: 2.3024 - val_accuracy: 0.6368\n","Epoch 21/30\n","286/286 [==============================] - 289s 1s/step - loss: 0.1306 - accuracy: 0.9578 - val_loss: 1.8679 - val_accuracy: 0.6391\n","Epoch 22/30\n","286/286 [==============================] - 274s 958ms/step - loss: 0.1299 - accuracy: 0.9577 - val_loss: 2.2776 - val_accuracy: 0.6464\n","Epoch 23/30\n","286/286 [==============================] - 274s 960ms/step - loss: 0.1236 - accuracy: 0.9602 - val_loss: 1.8687 - val_accuracy: 0.6449\n","Epoch 24/30\n","286/286 [==============================] - 280s 979ms/step - loss: 0.1236 - accuracy: 0.9600 - val_loss: 1.8245 - val_accuracy: 0.6470\n","Epoch 25/30\n","286/286 [==============================] - 302s 1s/step - loss: 0.1049 - accuracy: 0.9675 - val_loss: 2.1540 - val_accuracy: 0.6432\n","Epoch 26/30\n","286/286 [==============================] - 288s 1s/step - loss: 0.1127 - accuracy: 0.9658 - val_loss: 2.2402 - val_accuracy: 0.6473\n","Epoch 27/30\n","286/286 [==============================] - 299s 1s/step - loss: 0.0995 - accuracy: 0.9658 - val_loss: 2.2316 - val_accuracy: 0.6330\n","Epoch 28/30\n","286/286 [==============================] - 296s 1s/step - loss: 0.1018 - accuracy: 0.9663 - val_loss: 2.0870 - val_accuracy: 0.6385\n","Epoch 29/30\n","286/286 [==============================] - 298s 1s/step - loss: 0.0998 - accuracy: 0.9677 - val_loss: 1.9993 - val_accuracy: 0.6491\n","Epoch 30/30\n","286/286 [==============================] - 291s 1s/step - loss: 0.1015 - accuracy: 0.9679 - val_loss: 2.2344 - val_accuracy: 0.6202\n","Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 128, 128, 32)      896       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 126, 126, 32)      9248      \n","                                                                 \n"," max_pooling2d (MaxPooling2D  (None, 63, 63, 32)       0         \n"," )                                                               \n","                                                                 \n"," dropout (Dropout)           (None, 63, 63, 32)        0         \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 63, 63, 64)        18496     \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 61, 61, 64)        36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPooling  (None, 30, 30, 64)       0         \n"," 2D)                                                             \n","                                                                 \n"," dropout_1 (Dropout)         (None, 30, 30, 64)        0         \n","                                                                 \n"," flatten (Flatten)           (None, 57600)             0         \n","                                                                 \n"," dense (Dense)               (None, 512)               29491712  \n","                                                                 \n"," dropout_2 (Dropout)         (None, 512)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 29,562,410\n","Trainable params: 29,562,410\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["\n","\n","#convert list to numpy array\n","X = np.array(X)\n","y = np.array(y)\n","print(\"X numpy array: \", type(X), X.shape)\n","print(\"y numpy array: \", type(y), y.shape)\n","# we already obtained the images in our X array and our label in our y array\n","# we might need to do the transfer learning .....\n","# we need to research transfer learning for the next part of the project\n","# after transfer learning\n","# Load data set\n","x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=2)\n","print(\"X_train: \", x_train.shape)\n","print(\"X_val: \", x_test.shape)\n","print(\"y_train: \", y_train.shape)\n","print(\"y_val: \", y_test.shape)\n","\n","# Normalize data set to 0-to-1 range\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","\n","# Convert class vectors to binary class matrices\n","y_train = to_categorical(y_train, 10)#\n","y_test = to_categorical(y_test, 10)\n","\n","# Create a model and add layers\n","model = Sequential()\n","\n","model.add(Conv2D(32, (3, 3), padding='same', input_shape=(128, 128, 3), activation=\"relu\"))\n","model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n","model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","\n","model.add(Flatten())\n","model.add(Dense(512, activation=\"relu\"))\n","model.add(Dropout(0.5))\n","model.add(Dense(10, activation=\"softmax\"))\n","\n","# Compile the model\n","model.compile(\n","    loss='categorical_crossentropy',\n","    optimizer='adam',\n","    metrics=['accuracy']\n",")\n","\n","# Print a summary of the model\n","model.summary()\n","\n","# Train the model\n","model.fit(x_train, y_train, batch_size=64, epochs=30, validation_data=(x_test, y_test), shuffle=True)\n","\n","model.summary()"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"DL_Animals_Model.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
